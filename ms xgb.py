#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split


# In[2]:


data = pd.read_csv('RF.csv')
df = pd.DataFrame(data)


# In[3]:


X = df.drop(['target'], axis=1)
y = df['target']


# In[4]:


target = 'target'
features = df.columns.drop(target)
print(data["target"].value_counts()) # é¡ºä¾¿æŸ¥çœ‹ä¸€ä¸‹æ ·æœ¬æ˜¯å¦å¹³è¡¡
np.random.seed(seed=5)


# In[5]:


# df = shuffle(df)
X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.3, random_state=0)


# In[6]:


import xgboost as xgb  # ç¡®ä¿ä½¿ç”¨æ­£å¸¸ç©ºæ ¼
from sklearn.model_selection import GridSearchCV


# In[7]:


# ä¿®æ­£åçš„ XGBoost æ¨¡å‹å‚æ•°ï¼ˆä½¿ç”¨æ­£å¸¸ç©ºæ ¼ï¼‰
params_xgb = {
    'learning_rate': 0.02,            # å­¦ä¹ ç‡ï¼Œæ§åˆ¶æ¯ä¸€æ­¥çš„æ­¥é•¿ï¼Œç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆã€‚å…¸å‹å€¼èŒƒå›´ï¼š0.01 - 0.1
    'booster': 'gbtree',              # æå‡æ–¹æ³•ï¼Œè¿™é‡Œä½¿ç”¨æ¢¯åº¦æå‡æ ‘ï¼ˆGradient Boosting Treeï¼‰
    'objective': 'binary:logistic',   # æŸå¤±å‡½æ•°ï¼Œè¿™é‡Œä½¿ç”¨é€»è¾‘å›å½’ï¼Œç”¨äºäºŒåˆ†ç±»ä»»åŠ¡
    'max_leaves': 127,                # æ¯æ£µæ ‘çš„å¶å­èŠ‚ç‚¹æ•°é‡ï¼Œæ§åˆ¶æ¨¡å‹å¤æ‚åº¦
    'verbosity': 1,                   # æ§åˆ¶ XGBoost è¾“å‡ºä¿¡æ¯çš„è¯¦ç»†ç¨‹åº¦
    'seed': 42,                       # éšæœºç§å­ï¼Œç”¨äºé‡ç°æ¨¡å‹çš„ç»“æœ
    'nthread': -1,                    # å¹¶è¡Œè¿ç®—çš„çº¿ç¨‹æ•°é‡ï¼Œ-1è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
    'colsample_bytree': 0.6,          # æ¯æ£µæ ‘éšæœºé€‰æ‹©çš„ç‰¹å¾æ¯”ä¾‹
    'subsample': 0.7,                 # æ¯æ¬¡è¿­ä»£æ—¶éšæœºé€‰æ‹©çš„æ ·æœ¬æ¯”ä¾‹
    'eval_metric': 'logloss'          # è¯„ä»·æŒ‡æ ‡ï¼Œä½¿ç”¨å¯¹æ•°æŸå¤±
}


# In[8]:


model_xgb = xgb.XGBClassifier(**params_xgb)


# In[9]:


# ä¿®æ­£åçš„å‚æ•°ç½‘æ ¼ï¼ˆä½¿ç”¨æ­£å¸¸ç©ºæ ¼ï¼‰
param_grid = {
    'n_estimators': [100, 200, 300, 400, 500],  # æ ‘çš„æ•°é‡
    'max_depth': [3, 4, 5, 6, 7],               # æ ‘çš„æ·±åº¦
    'learning_rate': [0.01, 0.02, 0.05, 0.1],   # å­¦ä¹ ç‡
}


# In[10]:


from sklearn.model_selection import GridSearchCV
import joblib

# ä½¿ç”¨GridSearchCVè¿›è¡Œç½‘æ ¼æœç´¢å’ŒkæŠ˜äº¤å‰éªŒè¯ï¼ˆä½¿ç”¨æ­£å¸¸ç©ºæ ¼ï¼‰
grid_search = GridSearchCV(
    estimator=model_xgb,
    param_grid=param_grid,
    scoring='neg_log_loss',  # è¯„ä»·æŒ‡æ ‡ä¸ºè´Ÿå¯¹æ•°æŸå¤±
    cv=5,                    # 5æŠ˜äº¤å‰éªŒè¯
    n_jobs=-1,               # å¹¶è¡Œè®¡ç®—
    verbose=1                # è¾“å‡ºè¯¦ç»†è¿›åº¦ä¿¡æ¯
)

# è®­ç»ƒæ¨¡å‹
grid_search.fit(X_train, y_train)

# è¾“å‡ºæœ€ä¼˜å‚æ•°
print("Best parameters found: ", grid_search.best_params_)
print("Best Log Loss score: ", -grid_search.best_score_)

# ä½¿ç”¨æœ€ä¼˜å‚æ•°è®­ç»ƒæ¨¡å‹
best_model = grid_search.best_estimator_

# ä¿å­˜æ¨¡å‹
joblib.dump(best_model, 'XGBoost.pkl')


# In[11]:


#!/usr/bin/env python
# coding: utf-8

import streamlit as st
import joblib
import pandas as pd
import shap
import matplotlib.pyplot as plt
import os

# --- 1. Model Loading ---
try:
    model_path = os.path.join(os.path.dirname(__file__), 'XGBoost.pkl')
    model = joblib.load(model_path)
except Exception as e:
    st.error(f"Model loading failed: {str(e)}")
    st.stop()

# --- 2. Interface Elements (English Only) ---
st.title("LARC Early Recurrence Predictor")

# Define feature names in EXACTLY the same order as during training
feature_names = ['SINIT', 'T', 'N', 'SIZE']  # Critical: Must match training order

# Input widgets with English labels
tumor_size = st.number_input("Tumor Size (cm)", 
                           min_value=0.1, 
                           max_value=10.0, 
                           value=1.0, 
                           step=0.1,
                           help="Diameter of the primary tumor")

n_status = st.selectbox("Lymph Node Status (cN)", 
                       options=[0, 1], 
                       format_func=lambda x: 'Negative (0)' if x == 0 else 'Positive (1)',
                       help="Presence of lymph node metastasis")

t_stage = st.selectbox("T Stage (cT)", 
                      options=[1, 2, 3, 4],
                      format_func=lambda x: f"cT{x}",
                      help="Tumor depth and local invasion")

sinit_class = st.selectbox("SINIT Classification", 
                         options=[1, 2, 3],
                         format_func=lambda x: f"SINIT{x}",
                         help="Tumor regression grading system")

# --- 3. Prediction Logic ---
if st.button("Predict Recurrence Risk"):
    try:
        # Prepare input data in correct order
        input_data = pd.DataFrame([[sinit_class, t_stage, n_status, tumor_size]], 
                                columns=feature_names)
        
        # Make prediction
        prediction = model.predict(input_data)[0]
        probabilities = model.predict_proba(input_data)[0]
        
        # Display results
        if prediction == 1:
            st.error(f"ğŸ”´ High Risk of Early Recurrence: {probabilities[1]:.1%}")
            st.warning("Clinical recommendation: Consider adjuvant therapy and close monitoring")
        else:
            st.success(f"ğŸŸ¢ Low Risk of Early Recurrence: {probabilities[0]:.1%}")
            st.info("Clinical recommendation: Standard follow-up protocol")
        
        # --- 4. SHAP Explanation ---
        with st.expander("Explain this prediction"):
            explainer = shap.TreeExplainer(model)
            shap_values = explainer.shap_values(input_data)
            
            st.subheader("Feature Importance")
            fig1, ax1 = plt.subplots()
            shap.summary_plot(shap_values, input_data, plot_type="bar", show=False)
            st.pyplot(fig1)
            
            st.subheader("Prediction Breakdown")
            fig2, ax2 = plt.subplots()
            shap.plots.waterfall(shap.Explanation(
                values=shap_values[0], 
                base_values=explainer.expected_value,
                feature_names=feature_names,
                data=input_data.iloc[0]))
            st.pyplot(fig2)
            
    except Exception as e:
        st.error("Prediction failed. Please check:")
        st.write(f"Technical details: {str(e)}")
        st.write("Common fixes:")
        st.write("1. Ensure all fields are completed")
        st.write("2. Verify model file exists")
        st.write("3. Check value ranges (especially tumor size)")
